{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "196e8b03-a3c9-4450-b411-83fb1488e285",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.1 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 20.5/44.1 kB 320.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 44.1/44.1 kB 538.0 kB/s eta 0:00:00\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp38-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp38-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from requests->transformers) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from requests->transformers) (2024.6.2)\n",
      "Downloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 2.8/10.0 MB 58.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.5/10.0 MB 58.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.1/10.0 MB 58.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 53.6 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "   ---------------------------------------- 0.0/447.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 447.5/447.5 kB 27.3 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.5-cp38-none-win_amd64.whl (286 kB)\n",
      "   ---------------------------------------- 0.0/286.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 286.2/286.2 kB ? eta 0:00:00\n",
      "Downloading tokenizers-0.20.3-cp38-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------  2.4/2.4 MB 76.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 50.5 MB/s eta 0:00:00\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "   ---------------------------------------- 0.0/179.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 179.6/179.6 kB ? eta 0:00:00\n",
      "Installing collected packages: safetensors, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.16.1 fsspec-2024.10.0 huggingface-hub-0.26.2 safetensors-0.4.5 tokenizers-0.20.3 transformers-4.46.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c308d9-bfdc-4a11-978b-99f4907f8e38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf_keras\n",
      "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading tf_keras-2.15.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tf_keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.7 MB 660.6 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 1.1/1.7 MB 13.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 18.1 MB/s eta 0:00:00\n",
      "Installing collected packages: tf_keras\n",
      "Successfully installed tf_keras-2.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tf_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4049f62-5eed-4544-891d-92b727cb195d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.34.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.32.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (7.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27fdb94c-4aee-48c4-a0a9-734db39e7ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a42d08ec17442fb6ee9487700b1a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\shko8\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c968420a1a034efcb5070d002cd19322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0783b29e43cd4566a13479a93f032b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef96c9ce09f4695ac13e1ecc537b682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감성분석 결과: POSITIVE, 감성스코어: 0.9999\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "clf = pipeline('sentiment-analysis')\n",
    "result = clf('what a beautiful day!')[0]\n",
    "print('감성분석 결과: %s, 감성스코어: %0.4f' % (result['label'], result['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ef4df0-ea2b-4ddb-b3ce-df298441e3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfb49e8bc1849da95120007df2e3be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\shko8\\.cache\\huggingface\\hub\\models--openai-community--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f483622ce44386b8243a3c8b520d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7986f5ed6c44cd9a57cebacf7a8a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb64403229a442eabfcda68126bab0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8604ad46b4f04a4f90885d369a6a607f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a9d23fd2894a74ae565160024a76dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice was beginning to get very tired of sitting by her sister on the bank, so her older sister went up to her room to lay her eyes on her, and she woke her up, and the old girl started talking very politely, and she asked\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text_generator = pipeline('text-generation')\n",
    "result = text_generator('Alice was beginning to get very tired of sitting by her sister on the bank,')\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58dba490-5188-48a4-977c-9df87f6d7c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Collecting torch\n",
      "  Downloading torch-2.4.1-cp38-cp38-win_amd64.whl.metadata (27 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.19.1-cp38-cp38-win_amd64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.4.1-cp38-cp38-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from torch) (3.16.1)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shko8\\.conda\\envs\\py3_8_5\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.4.1-cp38-cp38-win_amd64.whl (199.4 MB)\n",
      "   ---------------------------------------- 0.0/199.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 2.8/199.4 MB 59.9 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 5.4/199.4 MB 58.4 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 8.1/199.4 MB 57.7 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 8.7/199.4 MB 46.7 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 9.1/199.4 MB 38.7 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 10.8/199.4 MB 38.5 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 13.5/199.4 MB 38.5 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 16.2/199.4 MB 38.5 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 17.2/199.4 MB 36.4 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 18.4/199.4 MB 31.2 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 21.0/199.4 MB 43.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 22.1/199.4 MB 40.9 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 22.3/199.4 MB 32.7 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 22.5/199.4 MB 29.7 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 22.9/199.4 MB 26.2 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 25.2/199.4 MB 25.1 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 27.8/199.4 MB 29.8 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 30.5/199.4 MB 29.8 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 31.6/199.4 MB 29.7 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 31.7/199.4 MB 26.2 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 31.8/199.4 MB 22.6 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 32.1/199.4 MB 20.5 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 33.6/199.4 MB 28.4 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 36.3/199.4 MB 28.4 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 39.1/199.4 MB 28.5 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 41.7/199.4 MB 28.5 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 44.4/199.4 MB 59.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 47.1/199.4 MB 59.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 49.6/199.4 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 52.0/199.4 MB 54.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 55.6/199.4 MB 59.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 58.3/199.4 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 61.0/199.4 MB 59.8 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 63.7/199.4 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 66.4/199.4 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 68.7/199.4 MB 54.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 71.4/199.4 MB 54.4 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 74.1/199.4 MB 54.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 76.8/199.4 MB 54.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 79.4/199.4 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 82.1/199.4 MB 59.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 85.7/199.4 MB 59.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 88.3/199.4 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 91.1/199.4 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 93.8/199.4 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 96.2/199.4 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 98.7/199.4 MB 54.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 99.0/199.4 MB 46.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 99.4/199.4 MB 38.6 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 101.8/199.4 MB 38.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 104.5/199.4 MB 38.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 107.2/199.4 MB 38.5 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 110.8/199.4 MB 59.5 MB/s eta 0:00:02\n",
      "   ---------------------- ---------------- 114.4/199.4 MB 59.8 MB/s eta 0:00:02\n",
      "   ---------------------- ---------------- 117.0/199.4 MB 59.5 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 117.7/199.4 MB 50.4 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 118.0/199.4 MB 40.9 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 119.5/199.4 MB 38.5 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 122.2/199.4 MB 38.5 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 124.9/199.4 MB 38.5 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 127.5/199.4 MB 38.5 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 130.3/199.4 MB 54.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 133.8/199.4 MB 59.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 136.5/199.4 MB 59.5 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 139.2/199.4 MB 59.5 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 139.7/199.4 MB 50.4 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 140.0/199.4 MB 40.9 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 140.8/199.4 MB 36.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 143.5/199.4 MB 36.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 144.8/199.4 MB 36.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 144.9/199.4 MB 32.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 144.9/199.4 MB 25.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 145.0/199.4 MB 23.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 145.3/199.4 MB 21.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 145.7/199.4 MB 19.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 146.0/199.4 MB 18.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 146.4/199.4 MB 16.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 147.0/199.4 MB 16.0 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 147.3/199.4 MB 14.9 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 148.4/199.4 MB 14.2 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 151.2/199.4 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 153.8/199.4 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 155.4/199.4 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 155.9/199.4 MB 24.2 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 156.4/199.4 MB 26.2 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 156.7/199.4 MB 24.3 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 158.1/199.4 MB 32.7 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 161.6/199.4 MB 31.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 164.3/199.4 MB 31.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 167.0/199.4 MB 54.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 169.7/199.4 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 172.5/199.4 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 175.2/199.4 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 175.7/199.4 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 177.7/199.4 MB 46.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 180.4/199.4 MB 46.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 183.1/199.4 MB 46.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 183.7/199.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 183.7/199.4 MB 34.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 183.8/199.4 MB 31.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 184.1/199.4 MB 26.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 184.4/199.4 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 186.5/199.4 MB 25.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 189.2/199.4 MB 25.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 191.2/199.4 MB 25.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 193.9/199.4 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  196.6/199.4 MB 54.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.3/199.4 MB 54.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 54.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 54.4 MB/s eta 0:00:01\n",
      "   --------------------------------------- 199.4/199.4 MB 31.2 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.19.1-cp38-cp38-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 79.9 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.4.1-cp38-cp38-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 51.2 MB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 43.9 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 2.7/6.2 MB 57.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.3/6.2 MB 57.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.7/6.2 MB 45.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 36.1 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 32.9 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, networkx, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39c0006a-8697-4f95-aecb-1fddbc32e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc4cb4ba-8710-4c99-bb21-cba1e3289f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no: 65%\n",
      "yes: 35%\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased-finetuned-mrpc')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'bert-base-cased-finetuned-mrpc'\n",
    ")\n",
    "\n",
    "input_sentence = 'She angered me with her inappropriate commetns, rumor-spreading, and disrespectfulness at the formal dinner table'\n",
    "target_sequence = 'She made me angry when she was rude at dinner'\n",
    "\n",
    "tokens = tokenizer(input_sentence, target_sequence, return_tensors='pt')\n",
    "\n",
    "logits = model(**tokens).logits\n",
    "\n",
    "results = torch.softmax(logits, dim=1).tolist()[0]\n",
    "\n",
    "for i, label in enumerate(['no', 'yes']):\n",
    "    print(f'{label}: {int(round(results[i]*100))}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e25fc340-5fd9-4a87-8c07-337cbf8532f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no: 95%\n",
      "yes: 5%\n"
     ]
    }
   ],
   "source": [
    "target_sequence = 'The boy quickly ran across the finish line, seizing yet another victory'\n",
    "tokens = tokenizer(input_sentence, target_sequence, return_tensors='pt')\n",
    "logits = model(**tokens).logits\n",
    "results = torch.softmax(logits, dim=1).tolist()[0]\n",
    "\n",
    "for i, label in enumerate(['no', 'yes']):\n",
    "    print(f'{label}: {int(round(results[i]*100))}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "943849e3-f53c-4e01-9018-2b91a90072a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set count:  1600\n",
      "Test set count:  400\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('movie_reviews')\n",
    "\n",
    "fileids = movie_reviews.fileids()\n",
    "\n",
    "reviews = [movie_reviews.raw(fileid) for fileid in fileids]\n",
    "categories = [movie_reviews.categories(fileid)[0] for fileid in fileids]\n",
    "\n",
    "label_dict = {'pos':1, 'neg':0}\n",
    "y = np.array([label_dict[c] for c in categories])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, y, test_size=0.2, random_state=7)\n",
    "\n",
    "print('Train set count: ', len(X_train))\n",
    "print('Test set count: ', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "351c37cb-d2b2-443c-9719-6b7bc46ec090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f89f98f5-68f6-46b4-b262-e313b07082e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a72ed29b9c44f9908fd64924be7430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466b59918ac94cdf98c8f821a4f526d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe857eb3d144fccb453cd9dc5da33f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59582f718b43469691c8d145fb41be9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK 영화리뷰 감성분석 정확도: 184\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'distilbert-base-uncased-finetuned-sst-2-english'\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased-finetuned-sst-2-english'\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "batch_size = 10\n",
    "y_pred = []\n",
    "\n",
    "num_batch = len(y_test)//batch_size\n",
    "\n",
    "for i in range(num_batch):\n",
    "    inputs = tokenizer(\n",
    "        X_test[i*batch_size:(i+1)*batch_size],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "    logits = model(**inputs).logits\n",
    "    pred = F.softmax(logits, dim=1)\n",
    "    results = pred.cpu().detach().numpy().argmax(axis=1)\n",
    "    y_pred.extend(results.tolist())\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "892db11a-77e3-460d-9419-40d4115d703d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK 영화리뷰 감성분석 정확도: 0.8425\n"
     ]
    }
   ],
   "source": [
    "score = sum(y_test == np.array(y_pred))/len(y_test)\n",
    "print('NLTK 영화리뷰 감성분석 정확도:',score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
